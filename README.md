---
# ğŸ¦ Loan Default Prediction â€“ End-to-End MLOps Project

This project implements an **end-to-end MLOps pipeline** for predicting loan defaults using the [LendingClub dataset](https://www.kaggle.com/wordsforthewise/lending-club).

It was built as part of the **DataTalksClub MLOps Zoomcamp capstone** and demonstrates how to move from a trained ML model to a **production-grade ML system** with automated retraining, deployment, monitoring, and CI/CD.

---

## ğŸ“Œ Project Overview

### Problem Statement
Loan default is a major risk for financial institutions, leading to revenue loss and operational costs. This project builds a machine learning pipeline to predict the likelihood of loan default and integrates the workflow into a production-ready MLOps system.

### Dataset
* **Source**: LendingClub Loan Dataset (public).
* **Cleaned version**: `gs://loan-default-artifacts-loan-default-mlops/data/loan_default_selected_features_clean.csv`
* **Features**: loan amount, interest rate, credit grade, revolving balance, etc.
* **Target variable**: `loan_status` (defaulted vs non-defaulted).

### Objectives
This project demonstrates the full MLOps lifecycle:

âœ… Train, evaluate, and register models with MLflow  
âœ… Automate workflows with Airflow DAGs  
âœ… Deploy models via Docker + MLflow REST API  
âœ… Daily batch prediction with Airflow  
âœ… Monitor drift and quality with Evidently  
âœ… Store artifacts in GCS (Terraform provisioned)  
âœ… CI/CD with GitHub Actions + testing  

---

## ğŸ—ï¸ Architecture & Tools
---

### High-Level Workflow

```mermaid
flowchart LR
    D[ğŸ“Š Data] --> T[ğŸ§  Training]
    T --> R[ğŸ“¦ MLflow Registry]
    R --> S[ğŸš€ Serving API]
    S --> P[ğŸ“ˆ Batch Predictions]
    P --> M[ğŸ›¡ï¸ Drift Detection]
````

---

### Detailed Architecture

```mermaid
flowchart LR
    subgraph Data["ğŸ“Š GCS Data"]
        A[loan_default_selected_features_clean.csv]
        B[batch_input.csv]
    end

    subgraph Training["ğŸ§  Training DAG"]
        A --> T1[train_with_mlflow.py]
        T1 --> MLflow[(MLflow Tracking & Registry)]
        T1 --> Artifacts[(GCS Artifacts)]
    end

    subgraph Registry["ğŸ“¦ MLflow Registry"]
        MLflow --> Staging[(Staging Alias)]
        MLflow --> Production[(Production Alias)]
    end

    subgraph Serving["ğŸš€ Model Serving"]
        Staging --> API["MLflow REST API (Docker)"]
    end

    subgraph Batch["ğŸ“ˆ Batch Prediction DAG"]
        B --> P1[batch_predict.py]
        P1 --> Predictions[(Predictions in GCS)]
        Predictions --> Marker[latest_prediction.txt]
    end

    subgraph Monitoring["ğŸ›¡ï¸ Monitoring DAG"]
        Marker --> M1[monitor_predictions.py (Evidently)]
        A --> M1
        M1 --> Reports[(Reports in GCS)]
    end
```

---

### Technologies

* **Cloud & IaC**: Google Cloud (GCS), Terraform
* **Tracking & Registry**: MLflow
* **Orchestration**: Apache Airflow
* **Serving**: MLflow REST API (Docker)
* **Monitoring**: Evidently
* **CI/CD**: GitHub Actions
* **Testing**: Pytest (unit + integration)

---

## ğŸ“‚ Project Structure

```bash
loan_default_prediction/
â”œâ”€â”€ airflow/                  # Airflow env & DAGs
â”‚   â”œâ”€â”€ dags/                 # Training, batch, monitoring, promotion DAGs
â”‚   â”œâ”€â”€ docker-compose.yaml   # Airflow + MLflow + Serve stack
â”‚   â”œâ”€â”€ start_all.sh          # Start services
â”‚   â”œâ”€â”€ stop_all.sh           # Stop services
â”‚   â””â”€â”€ keys/                 # GCP service account (not in repo)
â”œâ”€â”€ data/                     # Training + batch data
â”‚   â”œâ”€â”€ loan_default_selected_features_clean.csv
â”‚   â””â”€â”€ batch_input.csv
â”œâ”€â”€ infra/terraform/          # GCP infrastructure IaC
â”‚   â”œâ”€â”€ main.tf variables.tf outputs.tf terraform.tfvars
â”œâ”€â”€ model/                    # MLflow-managed models
â”œâ”€â”€ src/                      # Core code
â”‚   â”œâ”€â”€ train_with_mlflow.py
â”‚   â”œâ”€â”€ batch_predict.py
â”‚   â”œâ”€â”€ monitor_predictions.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ tests/                    # Unit & integration tests
â”‚   â”œâ”€â”€ test_utils.py
â”‚   â”œâ”€â”€ test_batch_prediction_integration.py
â”‚   â””â”€â”€ test_prediction_integration.py
â”œâ”€â”€ .env                      # Environment variables
â”œâ”€â”€ Makefile                  # Common commands
â”œâ”€â”€ requirements*.txt         # Dependencies
â”œâ”€â”€ Dockerfile*               # Service Dockerfiles
â”œâ”€â”€ architecture.html          # Interactive architecture diagram
â””â”€â”€ README.md
```

> ğŸ”‘ Notes
>
> * Secrets (service account keys) are **not committed**.
> * `mlruns/` and `artifacts/` are runtime only (in `.gitignore`).
> * Fully reproducible with `make start` + `make terraform-apply`.

---

## â˜ï¸ Cloud Infrastructure

Provisioned with Terraform:

* **Bucket**: `loan-default-artifacts-<project_id>`
* Stores: training data, batch inputs, predictions, MLflow artifacts.
* Features: versioning + lifecycle rules.

Auth: service account key â†’ `/opt/airflow/keys/gcs-service-account.json`

Fallback: if no GCP, everything runs locally with `mlruns/` and `artifacts/`.

Commands:

```bash
make terraform-init
make terraform-plan
make terraform-apply
make terraform-destroy
```

---

## ğŸ¯ MLflow Tracking & Registry

* **Metrics**: AUC, F1, Precision, Recall
* **Artifacts**: ROC, confusion matrix, feature importance plots
* **Registry**:

  * Model name: `loan_default_model`
  * Aliases: `staging`, `production`
* **Integration**: Training DAG logs â†’ MLflow; Promotion DAG updates aliases

Access UI: [http://localhost:5000](http://localhost:5000)

---

## âš™ï¸ Airflow Orchestration

DAGs:

1. `train_model_with_mlflow`: weekly retraining
2. `promote_model_dag`: staging â†’ production promotion
3. `batch_prediction_dag`: daily batch predictions â†’ GCS
4. `monitoring_dag`: Evidently drift detection

UI: [http://localhost:8080](http://localhost:8080)

---

## ğŸš€ Model Deployment

* **Service**: MLflow REST API in `serve` container
* **Endpoint**: `http://localhost:5001/invocations`

Test:

```bash
curl -X POST http://localhost:5001/invocations \
  -H "Content-Type: application/json" \
  -d @data/sample_input.json
```

---

## ğŸ“Š Monitoring

* **Evidently** monitors drift and prediction quality
* Reports â†’ stored in GCS
* Extendable alerts â†’ Slack/Email

---

## ğŸ§ª Reproducibility & Best Practices

* Fully Dockerized (Airflow, MLflow, Serve, Terraform)
* Makefile automation (`make start`, `make stop`, `make integration-tests`)
* Unit + integration tests with pytest
* CI/CD with GitHub Actions (lint + tests)
* Code quality: Black + Flake8

---

---

## ğŸš€ Quickstart

```bash
# 1. Clone
git clone https://github.com/your-username/loan_default_prediction.git
cd loan_default_prediction

# 2. Keys
mkdir keys && cp gcs-service-account.json keys/

# 3. Start services
make start

# 4. Provision infra
make terraform-init
make terraform-apply

# 5. Trigger DAGs in Airflow UI
#    http://localhost:8080

# 6. Test API
curl -X POST http://localhost:5001/invocations \
  -H "Content-Type: application/json" \
  -d @data/sample_input.json

# 7. Stop services
make stop
```

---

## ğŸ› Known Issues & Troubleshooting

* Airflow fails â†’ run `docker compose -f airflow/docker-compose.yaml run --rm airflow-init`
* MLflow â€œnot foundâ€ â†’ trigger `train_model_with_mlflow` DAG
* GCS 403 â†’ check IAM roles on service account
* Integration tests fail â†’ use `make integration-tests` (runs inside container)
* Platform mismatch (M1 Macs) â†’ build with `--platform linux/amd64`

---

## ğŸ™ Acknowledgements

Developed as part of **DataTalksClub MLOps Zoomcamp**.

Thanks to the instructors, mentors, and community for guidance and feedback.

---